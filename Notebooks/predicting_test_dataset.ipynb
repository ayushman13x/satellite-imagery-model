{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fdef2a-022e-4f29-be94-eb5f45522fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Integrity Report ---\n",
      "Total rows in test2.xlsx: 5396\n",
      "Total images in folder  : 5396\n",
      "‚úÖ Success: Every row in the Excel file has a matching image.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load your test data\n",
    "test_df = pd.read_excel('test2.xlsx')\n",
    "expected_ids = set(test_df['id'].astype(str))\n",
    "\n",
    "# 2. List the actual images downloaded\n",
    "image_folder = 'test_images_final'\n",
    "downloaded_images = [f.replace('.jpg', '') for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
    "downloaded_ids = set(downloaded_images)\n",
    "\n",
    "# 3. Compare\n",
    "missing_images = expected_ids - downloaded_ids\n",
    "extra_images = downloaded_ids - expected_ids\n",
    "\n",
    "print(f\"--- Data Integrity Report ---\")\n",
    "print(f\"Total rows in test2.xlsx: {len(expected_ids)}\")\n",
    "print(f\"Total images in folder  : {len(downloaded_ids)}\")\n",
    "\n",
    "if len(missing_images) == 0:\n",
    "    print(\"‚úÖ Success: Every row in the Excel file has a matching image.\")\n",
    "else:\n",
    "    print(f\"‚ùå Warning: {len(missing_images)} images are MISSING.\")\n",
    "    print(f\"Sample missing IDs: {list(missing_images)[:5]}\")\n",
    "\n",
    "if len(extra_images) > 0:\n",
    "    print(f\"üí° Note: There are {len(extra_images)} extra images in the folder not in test2.xlsx.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facd8e04-241d-4eb7-bdd5-6a4105a66f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vision Model is restored and ready.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_vision_model():\n",
    "    # Use MobileNetV2 with ImageNet weights as you did before\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False \n",
    "    \n",
    "    # Replicate your exact Sequential structure\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1) \n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "vision_model = build_vision_model()\n",
    "print(\"‚úÖ Vision Model is restored and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba189a3-42fa-46d4-baaa-47db19897c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for 5404 images...\n",
      "‚úÖ Extraction Complete! Shape: (5404, 1280)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load your test data\n",
    "test_df = pd.read_excel('test2.xlsx')\n",
    "ids = test_df['id'].values\n",
    "all_test_features = []\n",
    "\n",
    "print(f\"Extracting features for {len(ids)} images...\")\n",
    "\n",
    "# Loop through in batches of 32 just like your training full_gen\n",
    "for i in range(0, len(ids), 32):\n",
    "    batch_ids = ids[i : i + 32]\n",
    "    batch_imgs = []\n",
    "    \n",
    "    for img_id in batch_ids:\n",
    "        path = os.path.join('test_house_images', f\"{img_id}.jpg\")\n",
    "        try:\n",
    "            # Replicate your exact loading and /255.0 normalization\n",
    "            img = tf.keras.preprocessing.image.load_img(path, target_size=(224, 224))\n",
    "            img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "            batch_imgs.append(img)\n",
    "        except Exception:\n",
    "            # Replicate your blank image fallback for missing/corrupted files\n",
    "            batch_imgs.append(np.zeros((224, 224, 3)))\n",
    "    \n",
    "    # Process batch through Layer 0 (MobileNet) and Layer 1 (Pooling)\n",
    "    imgs_array = np.array(batch_imgs)\n",
    "    x = vision_model.layers[0](imgs_array)\n",
    "    x = vision_model.layers[1](x)\n",
    "    \n",
    "    all_test_features.append(x.numpy())\n",
    "\n",
    "# Stack into the final 1280-column matrix\n",
    "visual_features_test = np.vstack(all_test_features)\n",
    "print(f\"‚úÖ Extraction Complete! Shape: {visual_features_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cb8a9e7-33eb-4c19-9b83-39c66bca6b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 'test_vis_df' created with shape (5404, 1280)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert your 1280-column matrix into a DataFrame\n",
    "# This matches the 'vis_i' naming convention used in training\n",
    "test_vis_df = pd.DataFrame(visual_features_test, columns=[f'vis_{i}' for i in range(1280)])\n",
    "\n",
    "print(f\"Success: 'test_vis_df' created with shape {test_vis_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df4440f-57da-4106-b64a-78a4da886774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Verification Report ---\n",
      "Total features model expects: 52\n",
      "Tabular features expected: 32\n",
      "Visual features (Top 20) expected: 20\n",
      "\n",
      "‚ùå MISSING TABULAR FEATURES (14):\n",
      "['year_sold', 'month_sold', 'living_to_lot_ratio', 'relative_living_size', 'relative_lot_size', 'luxury_index', 'total_rooms', 'avg_room_size', 'house_age', 'years_since_update', 'is_classic', 'bath_per_bed', 'sqft_per_bedroom', 'sqft_grade']\n",
      "Tip: Check your apply_tabular_engineering function for typos.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1. Load the master list of features the model expects\n",
    "final_cols = joblib.load('final_feature_list.pkl')\n",
    "\n",
    "# 2. Identify the expected tabular and visual features\n",
    "expected_tabular = [f for f in final_cols if not f.startswith('vis_')]\n",
    "expected_visual = [f for f in final_cols if f.startswith('vis_')]\n",
    "\n",
    "# 3. Identify what is currently in your DataFrames\n",
    "current_tabular = set(test_df.columns)\n",
    "current_visual = set(test_vis_df.columns)\n",
    "\n",
    "# 4. Find the missing pieces\n",
    "missing_tabular = [f for f in expected_tabular if f not in current_tabular]\n",
    "missing_visual = [f for f in expected_visual if f not in current_visual]\n",
    "\n",
    "print(\"--- Feature Verification Report ---\")\n",
    "print(f\"Total features model expects: {len(final_cols)}\")\n",
    "print(f\"Tabular features expected: {len(expected_tabular)}\")\n",
    "print(f\"Visual features (Top 20) expected: {len(expected_visual)}\")\n",
    "\n",
    "if not missing_tabular and not missing_visual:\n",
    "    print(\"\\n‚úÖ SUCCESS: All features are present. You can proceed to prediction.\")\n",
    "else:\n",
    "    if missing_tabular:\n",
    "        print(f\"\\n‚ùå MISSING TABULAR FEATURES ({len(missing_tabular)}):\")\n",
    "        print(missing_tabular)\n",
    "        print(\"Tip: Check your apply_tabular_engineering function for typos.\")\n",
    "    \n",
    "    if missing_visual:\n",
    "        print(f\"\\n‚ùå MISSING VISUAL FEATURES ({len(missing_visual)}):\")\n",
    "        print(missing_visual)\n",
    "        print(\"Tip: Ensure you converted your extracted matrix into a DataFrame with 'vis_i' column names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ec11b0-4cad-447d-9647-362d0cb9a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 14 Features engineered successfully with 2015 baseline.\n"
     ]
    }
   ],
   "source": [
    "# 1. Date-based features (Assuming 'date' column exists in test2.xlsx)\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "test_df['year_sold'] = test_df['date'].dt.year\n",
    "test_df['month_sold'] = test_df['date'].dt.month\n",
    "\n",
    "# 2. Space and Ratio features\n",
    "test_df['living_to_lot_ratio'] = test_df['sqft_living'] / test_df['sqft_lot'].replace(0, 1)\n",
    "test_df['relative_living_size'] = test_df['sqft_living'] / test_df['sqft_living15'].replace(0, 1)\n",
    "test_df['relative_lot_size'] = test_df['sqft_lot'] / test_df['sqft_lot15'].replace(0, 1)\n",
    "test_df['sqft_grade'] = test_df['sqft_living'] * test_df['grade']\n",
    "\n",
    "# 3. Room-based features\n",
    "test_df['total_rooms'] = test_df['bedrooms'] + test_df['bathrooms']\n",
    "test_df['avg_room_size'] = test_df['sqft_living'] / test_df['total_rooms'].replace(0, 1)\n",
    "test_df['bath_per_bed'] = test_df['bathrooms'] / test_df['bedrooms'].replace(0, 1)\n",
    "test_df['sqft_per_bedroom'] = test_df['sqft_living'] / test_df['bedrooms'].replace(0, 1)\n",
    "\n",
    "# 4. Quality and Age features (USING YOUR 2015 LOGIC)\n",
    "test_df['luxury_index'] = test_df['condition'] * test_df['grade']\n",
    "test_df['house_age'] = 2015 - test_df['yr_built']\n",
    "test_df['years_since_update'] = 2015 - test_df[['yr_built', 'yr_renovated']].max(axis=1)\n",
    "test_df['is_classic'] = test_df['yr_built'].apply(lambda x: 1 if x < 1940 else 0)\n",
    "\n",
    "print(\"‚úÖ 14 Features engineered successfully with 2015 baseline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cdd3578-c79b-4d01-94f1-a1c5beb57ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual Feature Preparation Complete.\n",
      "Original features: 1280\n",
      "Selected 'Golden' features: 20\n",
      "Sample of selected columns: ['vis_84', 'vis_111', 'vis_193', 'vis_211', 'vis_276']\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify which 'vis_' columns the model expects\n",
    "expected_vis_cols = [f for f in final_cols if f.startswith('vis_')]\n",
    "\n",
    "# 2. Select ONLY those 20 columns from your 1280-column dataframe\n",
    "test_vis_selected = test_vis_df[expected_vis_cols]\n",
    "\n",
    "print(f\"Visual Feature Preparation Complete.\")\n",
    "print(f\"Original features: {test_vis_df.shape[1]}\")\n",
    "print(f\"Selected 'Golden' features: {test_vis_selected.shape[1]}\")\n",
    "print(f\"Sample of selected columns: {expected_vis_cols[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf4657e-8a8c-4944-95d8-6e26e9ea7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained XGBoost model\n",
    "final_hybrid_model = joblib.load('honest_hybrid_k20_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e50736-8b40-4cd7-a2b4-f81ba209b808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting prices...\n"
     ]
    }
   ],
   "source": [
    "# 1. Combine the 32 Tabular + 20 Visual features\n",
    "# We reset index to ensure rows line up perfectly\n",
    "X_test_final_combined = pd.concat([test_df.reset_index(drop=True), \n",
    "                                  test_vis_selected.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 2. Force the columns into the EXACT order the model expects\n",
    "X_test_final = X_test_final_combined[final_cols]\n",
    "\n",
    "# 3. Generate Predictions\n",
    "print(\"Predicting prices...\")\n",
    "log_preds = final_hybrid_model.predict(X_test_final)\n",
    "\n",
    "# 4. Reverse the log transformation (np.expm1) to get real prices\n",
    "test_df['predicted_price'] = np.expm1(log_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495c6786-72d1-4e21-a155-0b98651d399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3.726483e+05\n",
      "1    8.818920e+05\n",
      "2    1.107493e+06\n",
      "3    1.813370e+06\n",
      "4    7.400080e+05\n",
      "Name: predicted_price, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(test_df['predicted_price'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "643d848a-dd4b-4141-bad7-1a626cddf9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DONE! Check your folder for 23117040_final.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. Save the final deliverable\n",
    "test_df[['id', 'predicted_price']].to_csv('23117040_final.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ DONE! Check your folder for 23117040_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b82fd5-7413-4cff-b759-8864872841df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
